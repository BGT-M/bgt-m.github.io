<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Lingrui Mei | Big Team (BGT-M) Group</title><link>https://bgt-m.github.io/author/lingrui-mei/</link><atom:link href="https://bgt-m.github.io/author/lingrui-mei/index.xml" rel="self" type="application/rss+xml"/><description>Lingrui Mei</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2025 00:00:00 +0000</lastBuildDate><image><url>https://bgt-m.github.io/media/icon_hu92c12b3a0bdf43c2212f3f443017d770_234085_512x512_fill_lanczos_center_3.png</url><title>Lingrui Mei</title><link>https://bgt-m.github.io/author/lingrui-mei/</link></image><item><title>\"Not Aligned\" is Not \"Malicious\": Being Careful about Hallucinations of Large Language Models' Jailbreak</title><link>https://bgt-m.github.io/publication/coling-2025-notalignedisnotmaliciousbeingcarefulabouthallucina/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/coling-2025-notalignedisnotmaliciousbeingcarefulabouthallucina/</guid><description/></item><item><title>a1: Steep Test-time Scaling Law via Environment Augmented Generation</title><link>https://bgt-m.github.io/publication/arxiv-2025-a1steeptesttimescalinglawviaenvironmentaugmentedge/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2025-a1steeptesttimescalinglawviaenvironmentaugmentedge/</guid><description/></item><item><title>Innate Reasoning is Not Enough: In-Context Learning Enhances Reasoning Large Language Models with Less Overthinking</title><link>https://bgt-m.github.io/publication/arxiv-2025-innatereasoningisnotenoughincontextlearningenhance/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2025-innatereasoningisnotenoughincontextlearningenhance/</guid><description/></item><item><title>Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models</title><link>https://bgt-m.github.io/publication/arxiv-2025-parametersvscontextfinegrainedcontrolofknowledgere/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2025-parametersvscontextfinegrainedcontrolofknowledgere/</guid><description/></item><item><title>Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?</title><link>https://bgt-m.github.io/publication/acl-2025-can_graph_descriptive_order/</link><pubDate>Wed, 16 Oct 2024 19:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/acl-2025-can_graph_descriptive_order/</guid><description/></item><item><title>\"Not Aligned\" is Not \"Malicious\": Being Careful about Hallucinations of Large Language Models' Jailbreak</title><link>https://bgt-m.github.io/publication/arxiv-2024-notalignedisnotmaliciousbeingcarefulabouthallucina/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-notalignedisnotmaliciousbeingcarefulabouthallucina/</guid><description/></item><item><title>Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities</title><link>https://bgt-m.github.io/publication/arxiv-2024-adaptivetokenbiaserknowledgeeditingviabiasingkeyen/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-adaptivetokenbiaserknowledgeeditingviabiasingkeyen/</guid><description/></item><item><title>Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities</title><link>https://bgt-m.github.io/publication/emnlp-2024-adaptivetokenbiaserknowledgeeditingviabiasingkeyen/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/emnlp-2024-adaptivetokenbiaserknowledgeeditingviabiasingkeyen/</guid><description/></item><item><title>Context-DPO: Aligning Language Models for Context-Faithfulness</title><link>https://bgt-m.github.io/publication/arxiv-2024-contextdpoaligninglanguagemodelsforcontextfaithful/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-contextdpoaligninglanguagemodelsforcontextfaithful/</guid><description/></item><item><title>Decoding by Contrasting Knowledge: Enhancing LLMs' Confidence on Edited Facts</title><link>https://bgt-m.github.io/publication/arxiv-2024-decodingbycontrastingknowledgeenhancingllmsconfide/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-decodingbycontrastingknowledgeenhancingllmsconfide/</guid><description/></item><item><title>HiddenGuard: Fine-Grained Safe Generation with Specialized Representation Router</title><link>https://bgt-m.github.io/publication/arxiv-2024-hiddenguardfinegrainedsafegenerationwithspecialize/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-hiddenguardfinegrainedsafegenerationwithspecialize/</guid><description/></item><item><title>Is Factuality Decoding a Free Lunch for LLMs? Evaluation on Knowledge Editing Benchmark</title><link>https://bgt-m.github.io/publication/arxiv-2024-isfactualitydecodingafreelunchforllmsevaluationonk/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-isfactualitydecodingafreelunchforllmsevaluationonk/</guid><description/></item><item><title>LPNL: Scalable Link Prediction with Large Language Models</title><link>https://bgt-m.github.io/publication/acl-2024-lpnlscalablelinkpredictionwithlargelanguagemodels/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/acl-2024-lpnlscalablelinkpredictionwithlargelanguagemodels/</guid><description/></item><item><title>Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models</title><link>https://bgt-m.github.io/publication/arxiv-2024-scalablelinkpredictiononlargescaleheterogeneousgra/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-scalablelinkpredictiononlargescaleheterogeneousgra/</guid><description/></item><item><title>SLANG: New Concept Comprehension of Large Language Models</title><link>https://bgt-m.github.io/publication/arxiv-2024-slangnewconceptcomprehensionoflargelanguagemodels/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-slangnewconceptcomprehensionoflargelanguagemodels/</guid><description/></item><item><title>SLANG: New Concept Comprehension of Large Language Models</title><link>https://bgt-m.github.io/publication/emnlp-2024-slangnewconceptcomprehensionoflargelanguagemodels/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/emnlp-2024-slangnewconceptcomprehensionoflargelanguagemodels/</guid><description/></item><item><title>StruEdit: Structured Outputs Enable the Fast and Accurate Knowledge Editing for Large Language Models</title><link>https://bgt-m.github.io/publication/arxiv-2024-strueditstructuredoutputsenablethefastandaccuratek/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://bgt-m.github.io/publication/arxiv-2024-strueditstructuredoutputsenablethefastandaccuratek/</guid><description/></item></channel></rss>